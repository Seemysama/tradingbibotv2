#!/bin/bash
# =============================================================================
# GPU SERVER LAUNCHER - Scripts de lancement sur PC Fixe
# =============================================================================
# Ã€ utiliser sur le serveur Ubuntu aprÃ¨s le dÃ©ploiement
# =============================================================================

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
cd "$SCRIPT_DIR"

source .venv_gpu/bin/activate

case "$1" in
    # =========================================================================
    # TRAINING
    # =========================================================================
    train)
        echo "ğŸ§  Lancement de l'entraÃ®nement GPU..."
        
        # ParamÃ¨tres par dÃ©faut ou custom
        DATA=${2:-"data/futures/BTC_USDT_5m_FULL.parquet"}
        EPOCHS=${3:-100}
        BATCH=${4:-1024}
        
        echo "  ğŸ“Š Data: $DATA"
        echo "  ğŸ”„ Epochs: $EPOCHS"
        echo "  ğŸ“¦ Batch size: $BATCH"
        
        python train_v2.py \
            --data "$DATA" \
            --epochs $EPOCHS \
            --batch-size $BATCH \
            --n-splits 5 \
            --device cuda
        ;;
    
    # =========================================================================
    # DATA DOWNLOAD
    # =========================================================================
    download)
        echo "ğŸ“¥ TÃ©lÃ©chargement des donnÃ©es massives..."
        
        PAIRS=${2:-"BTC/USDT,ETH/USDT,SOL/USDT"}
        TF=${3:-"5m"}
        
        echo "  ğŸ’¹ Paires: $PAIRS"
        echo "  â±ï¸  Timeframe: $TF"
        
        python tools/massive_ingest.py \
            --pairs $PAIRS \
            --timeframes $TF \
            --start 2020-01-01 \
            --consolidate
        ;;
    
    # =========================================================================
    # API BACKEND
    # =========================================================================
    api)
        echo "ğŸŒ Lancement de l'API Backend..."
        echo "  ğŸ”— URL: http://0.0.0.0:8000"
        
        uvicorn api.app:app \
            --host 0.0.0.0 \
            --port 8000 \
            --reload
        ;;
    
    api-prod)
        echo "ğŸŒ Lancement de l'API Backend (PRODUCTION)..."
        echo "  ğŸ”— URL: http://0.0.0.0:8000"
        
        uvicorn api.app:app \
            --host 0.0.0.0 \
            --port 8000 \
            --workers 4
        ;;
    
    # =========================================================================
    # GPU INFO
    # =========================================================================
    gpu)
        echo "ğŸ–¥ï¸ Information GPU:"
        nvidia-smi
        echo ""
        python -c "
import torch
print(f'PyTorch: {torch.__version__}')
print(f'CUDA: {torch.version.cuda}')
print(f'cuDNN: {torch.backends.cudnn.version()}')
print(f'GPU: {torch.cuda.get_device_name(0)}')
print(f'VRAM Total: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')
print(f'VRAM Libre: {torch.cuda.memory_reserved(0) / 1024**3:.1f} GB rÃ©servÃ©e')
"
        ;;
    
    # =========================================================================
    # TEST
    # =========================================================================
    test)
        echo "ğŸ§ª Test des modules..."
        python -c "
from src.features_pro import FeatureEngineerPro
from src.ai.transformer_pro import TransformerPro, TransformerConfig
import torch

print(f'âœ… CUDA disponible: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'âœ… GPU: {torch.cuda.get_device_name(0)}')

config = TransformerConfig(n_features=39, n_classes=3, seq_length=128)
model = TransformerPro(config).cuda()
print(f'âœ… ModÃ¨le sur GPU: {next(model.parameters()).device}')

x = torch.randn(32, 128, 39).cuda()
out = model(x)
print(f'âœ… Forward pass OK: {out[\"logits\"].shape}')
"
        ;;
    
    # =========================================================================
    # STATUS
    # =========================================================================
    status)
        echo "ğŸ“Š Status du systÃ¨me:"
        echo ""
        echo "ğŸ“ DonnÃ©es disponibles:"
        ls -lh data/futures/*.parquet 2>/dev/null || echo "  (aucune)"
        ls -lh data/massive/*.parquet 2>/dev/null || echo "  (aucune)"
        echo ""
        echo "ğŸ§  ModÃ¨les disponibles:"
        ls -lh models/*.pth 2>/dev/null || echo "  (aucun)"
        echo ""
        echo "ğŸ–¥ï¸ GPU:"
        nvidia-smi --query-gpu=name,memory.used,memory.total,utilization.gpu --format=csv,noheader
        ;;
    
    # =========================================================================
    # TRAIN ALL (Multi-GPU / Multi-Pair)
    # =========================================================================
    train-all)
        echo "ğŸš€ EntraÃ®nement sur toutes les paires..."
        
        for PAIR in BTC_USDT ETH_USDT SOL_USDT; do
            DATA="data/futures/${PAIR}_5m_FULL.parquet"
            if [ -f "$DATA" ]; then
                echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
                echo "Training $PAIR..."
                python train_v2.py \
                    --data "$DATA" \
                    --epochs 100 \
                    --batch-size 1024 \
                    --output "models/${PAIR}"
            else
                echo "âš ï¸ DonnÃ©es non trouvÃ©es: $DATA"
            fi
        done
        ;;
    
    # =========================================================================
    # HELP
    # =========================================================================
    *)
        echo "ğŸ¦ Trading Engine V2 - GPU Server Commands"
        echo ""
        echo "Usage: ./server.sh <command> [options]"
        echo ""
        echo "Commands:"
        echo "  train [data] [epochs] [batch]  - EntraÃ®ner le modÃ¨le"
        echo "  train-all                      - EntraÃ®ner sur toutes les paires"
        echo "  download [pairs] [timeframe]   - TÃ©lÃ©charger les donnÃ©es"
        echo "  api                            - Lancer l'API (dev)"
        echo "  api-prod                       - Lancer l'API (production)"
        echo "  gpu                            - Afficher les infos GPU"
        echo "  test                           - Tester les modules"
        echo "  status                         - Afficher le status"
        echo ""
        echo "Exemples:"
        echo "  ./server.sh train"
        echo "  ./server.sh train data/futures/BTC_USDT_5m_FULL.parquet 200 2048"
        echo "  ./server.sh download 'BTC/USDT,ETH/USDT,SOL/USDT' 5m"
        echo "  ./server.sh api"
        ;;
esac
